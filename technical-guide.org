#+TITLE: Claude Code Metrics Lab - Comprehensive Technical Guide
#+AUTHOR: aygp-dr
#+DATE: 2025-01-24
#+OPTIONS: toc:2 num:t
#+PROPERTY: header-args :mkdirp yes

* Table of Contents :TOC:
- [[#introduction][üìö Introduction]]
- [[#architecture-overview][üèóÔ∏è Architecture Overview]]
- [[#core-components][üîß Core Components]]
- [[#api-documentation][üì° API Documentation]]
- [[#configuration-guide][‚öôÔ∏è Configuration Guide]]
- [[#deployment-guide][üöÄ Deployment Guide]]
- [[#code-examples][üíª Code Examples]]
- [[#monitoring-and-dashboards][üìä Monitoring and Dashboards]]
- [[#troubleshooting][üîç Troubleshooting]]
- [[#faq][‚ùì FAQ]]
- [[#best-practices][‚ú® Best Practices]]
- [[#performance-optimization][‚ö° Performance Optimization]]

* üìö Introduction

The Claude Code Metrics Lab is a comprehensive educational framework and production-ready telemetry system designed to monitor, analyze, and optimize Claude Code usage. Born from real-world experience where a single overnight experiment cost $27.81, this project demonstrates the critical importance of understanding AI-powered development tool costs and usage patterns.

** üîë Key Features

- *OpenTelemetry-based Architecture*: Industry-standard observability framework
- *Contract-Driven Development*: Complete API specifications for every component
- *Educational Focus*: Learn telemetry concepts through systematic debugging
- *Production-Tested*: Real data from Claude Opus 4 experiments
- *Cost Awareness*: Discovered 2,000x cost variance in operations
- *Comprehensive Testing*: 54 test scenarios covering all configurations

** üí° Why This Project Matters

During Phase 1 experiments, we discovered that Claude Code operations can range from $0.0007 to $1.44 per operation‚Äîa 2,000x variance. Without proper monitoring, costs can escalate rapidly. This lab provides the tools and knowledge to implement effective telemetry for AI-powered development tools.

* üèóÔ∏è Architecture Overview

The Claude Code Metrics Lab implements a 4-layer telemetry architecture designed for both educational clarity and production reliability.

** üìä System Architecture Diagram

#+BEGIN_SRC mermaid
graph TB
    subgraph "Application Layer"
        CC[Claude Code] --> ME[Metric Events]
        ME --> LV[Local Validation]
    end
    
    subgraph "Collection Layer"
        LV --> LP[Logging Proxy]
        LP --> OC[OTLP Collector]
        OC --> PV[Protocol Validation]
    end
    
    subgraph "Storage Layer"
        PV --> PT[Prometheus TSDB]
        PT --> QI[Query Interface]
        QI --> DI[Data Integrity]
    end
    
    subgraph "Visualization Layer"
        DI --> GD[Grafana Dashboards]
        GD --> AM[Alert Manager]
        AM --> VV[Visual Validation]
    end
#+END_SRC

** üìã Layer Responsibilities

*** 1. Application Layer
- *Purpose*: Generate and validate metrics at the source
- *Components*: Claude Code integration, metric generation, local validation
- *Key Features*:
  - JSON Schema validation
  - Threshold monitoring
  - Session tracking
  - Error classification

*** 2. Collection Layer
- *Purpose*: Aggregate and process metrics
- *Components*: Logging Proxy, OTLP Collector, protocol handlers
- *Key Features*:
  - Multiple export formats (JSON, Prometheus, OTLP)
  - Protocol conversion (gRPC, HTTP/Protobuf, HTTP/JSON)
  - Payload inspection and debugging
  - Batch processing and buffering

*** 3. Storage Layer
- *Purpose*: Persist and query metrics
- *Components*: Prometheus TSDB, query API, retention policies
- *Key Features*:
  - Time-series data optimization
  - Efficient compression
  - PromQL query language
  - Data integrity verification

*** 4. Visualization Layer
- *Purpose*: Present insights and enable monitoring
- *Components*: Grafana dashboards, Alert Manager, visual analytics
- *Key Features*:
  - Real-time dashboards
  - Cost projections
  - Usage patterns
  - Alert notifications

** üîÑ Data Flow

#+BEGIN_SRC python
# Example metric flow through the architecture
metric = {
    "name": "claude_code_tokens_total",
    "value": 1500,
    "labels": {
        "model": "claude-opus-4",
        "project": "metrics-lab",
        "operation": "code_generation"
    },
    "timestamp": 1748050701
}

# 1. Application Layer: Generated by Claude Code
# 2. Collection Layer: Processed by Logging Proxy
# 3. Storage Layer: Stored in Prometheus
# 4. Visualization Layer: Displayed in Grafana
#+END_SRC

* üîß Core Components

** 1. Logging Proxy (=src/logging_proxy.py=)

The Logging Proxy is the heart of the telemetry system, providing configurable metric collection with comprehensive validation and debugging capabilities.

*** Key Features
- *Schema Validation*: Ensures metric integrity
- *Multiple Output Formats*: JSON, Prometheus, OTLP
- *Threshold Monitoring*: Real-time alerting
- *Session Analytics*: Track usage patterns
- *Debugging Mode*: Payload inspection

*** Implementation Details

#+BEGIN_SRC python
from typing import Dict, Any, Optional, List
import json
import jsonschema
import yaml
from datetime import datetime
from pathlib import Path

class LoggingProxy:
    """Advanced logging proxy for OpenTelemetry metrics with validation."""
    
    def __init__(self, config_path: str = "config/logging_proxy.yaml"):
        """Initialize with configuration file."""
        self.config = self._load_config(config_path)
        self.metrics_buffer: List[Dict[str, Any]] = []
        self.session_id = f"session-{int(datetime.now().timestamp())}"
        
    def validate_metric(self, metric: Dict[str, Any]) -> bool:
        """Validate metric against JSON schema."""
        schema = {
            "type": "object",
            "required": ["name", "value", "timestamp"],
            "properties": {
                "name": {"type": "string", "pattern": "^claude_code_.*"},
                "value": {"type": "number", "minimum": 0},
                "timestamp": {"type": "integer"},
                "labels": {
                    "type": "object",
                    "properties": {
                        "model": {"enum": self.config["validation"]["allowed_models"]},
                        "project": {"type": "string"},
                        "operation": {"type": "string"}
                    }
                }
            }
        }
        
        try:
            jsonschema.validate(metric, schema)
            return True
        except jsonschema.ValidationError as e:
            self._log_validation_error(metric, e)
            return False
    
    def process_metric(self, metric: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Process and enrich metric with additional context."""
        if not self.validate_metric(metric):
            return None
            
        # Enrich with session context
        metric["session_id"] = self.session_id
        metric["processed_at"] = datetime.now().isoformat()
        
        # Check thresholds
        self._check_thresholds(metric)
        
        # Buffer for batch processing
        self.metrics_buffer.append(metric)
        
        # Export if buffer is full
        if len(self.metrics_buffer) >= self.config["export"]["batch_size"]:
            self.export_metrics()
            
        return metric
    
    def _check_thresholds(self, metric: Dict[str, Any]) -> None:
        """Check metric against configured thresholds."""
        thresholds = self.config["monitoring"]["thresholds"]
        
        if metric["name"] == "claude_code_tokens_total":
            if metric["value"] > thresholds["max_tokens_per_operation"]:
                self._trigger_alert("high_token_usage", metric)
                
        elif metric["name"] == "claude_code_cost_usd":
            if metric["value"] > thresholds["max_cost_per_operation"]:
                self._trigger_alert("high_cost", metric)
#+END_SRC

** 2. Metrics Integration (=src/metrics_integration.py=)

Provides seamless integration between Claude Code and the telemetry pipeline.

*** Key Features
- *OpenTelemetry Integration*: Standard observability
- *Metric Aggregation*: Combine related metrics
- *Error Handling*: Graceful degradation
- *Performance Optimization*: Minimal overhead

*** Implementation Example

#+BEGIN_SRC python
from opentelemetry import metrics
from opentelemetry.exporter.otlp.proto.grpc.metric_exporter import OTLPMetricExporter
from opentelemetry.sdk.metrics import MeterProvider
from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader
import os

class MetricsIntegration:
    """Integrate logging proxy with OpenTelemetry metrics collection."""
    
    def __init__(self, endpoint: str = "localhost:4317"):
        """Initialize OpenTelemetry metrics provider."""
        # Configure OTLP exporter
        exporter = OTLPMetricExporter(
            endpoint=endpoint,
            insecure=True,
            headers=(("api-key", os.getenv("OTEL_API_KEY")),) if os.getenv("OTEL_API_KEY") else None
        )
        
        # Create metric reader with 30-second export interval
        reader = PeriodicExportingMetricReader(
            exporter=exporter,
            export_interval_millis=30000
        )
        
        # Set up meter provider
        provider = MeterProvider(metric_readers=[reader])
        metrics.set_meter_provider(provider)
        
        # Create meter for Claude Code metrics
        self.meter = metrics.get_meter("claude_code_metrics", "1.0.0")
        self._create_instruments()
        
    def _create_instruments(self):
        """Create metric instruments for Claude Code."""
        # Token counters
        self.token_counter = self.meter.create_counter(
            name="claude_code_tokens_total",
            description="Total tokens used by Claude Code",
            unit="tokens"
        )
        
        # Cost tracker
        self.cost_counter = self.meter.create_counter(
            name="claude_code_cost_usd",
            description="Cost of Claude Code operations in USD",
            unit="USD"
        )
        
        # Operation histogram
        self.operation_duration = self.meter.create_histogram(
            name="claude_code_operation_duration",
            description="Duration of Claude Code operations",
            unit="seconds"
        )
        
        # Active sessions gauge
        self.active_sessions = self.meter.create_up_down_counter(
            name="claude_code_active_sessions",
            description="Number of active Claude Code sessions"
        )
    
    def record_operation(self, operation_type: str, tokens: int, cost: float, duration: float, model: str):
        """Record a Claude Code operation."""
        labels = {
            "operation": operation_type,
            "model": model,
            "project": self._get_current_project()
        }
        
        # Record metrics
        self.token_counter.add(tokens, labels)
        self.cost_counter.add(cost, labels)
        self.operation_duration.record(duration, labels)
        
        # Log high-cost operations
        if cost > 0.10:  # $0.10 threshold
            self._log_expensive_operation(operation_type, cost, model)
#+END_SRC

** 3. Test Matrix (=test_matrix.py=)

Comprehensive testing framework that validates all possible telemetry configurations.

*** Test Coverage
- *54 Test Scenarios*: All configuration permutations
- *Export Formats*: OTLP, Prometheus, Console, Logging, None
- *Protocols*: gRPC, HTTP/Protobuf, HTTP/JSON
- *Error Scenarios*: Timeouts, invalid endpoints, auth failures
- *Performance Tests*: High-frequency metrics, load testing

*** Implementation

#+BEGIN_SRC python
import itertools
import asyncio
from typing import List, Dict, Any, Tuple
import yaml
import json
from datetime import datetime

class TelemetryTestMatrix:
    """Comprehensive test matrix for telemetry configurations."""
    
    def __init__(self):
        self.exporters = ["otlp", "prometheus", "console", "logging", "none"]
        self.protocols = ["grpc", "http/protobuf", "http/json"]
        self.error_scenarios = ["timeout", "invalid_endpoint", "auth_failure", "malformed_data"]
        self.results: List[Dict[str, Any]] = []
        
    def generate_test_matrix(self) -> List[Tuple[str, str, str]]:
        """Generate all test permutations."""
        matrix = []
        
        # Standard configurations
        for exporter, protocol in itertools.product(self.exporters, self.protocols):
            if self._is_valid_combination(exporter, protocol):
                matrix.append((exporter, protocol, "normal"))
                
        # Error scenarios
        for exporter, error in itertools.product(self.exporters, self.error_scenarios):
            if exporter != "none":  # Skip error tests for 'none' exporter
                matrix.append((exporter, "default", error))
                
        return matrix
    
    async def run_test_suite(self) -> Dict[str, Any]:
        """Execute all tests in the matrix."""
        matrix = self.generate_test_matrix()
        total_tests = len(matrix)
        
        print(f"Starting telemetry test matrix with {total_tests} scenarios...")
        
        # Run tests concurrently in batches
        batch_size = 10
        for i in range(0, total_tests, batch_size):
            batch = matrix[i:i + batch_size]
            tasks = [self._run_single_test(*config) for config in batch]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Process results
            for config, result in zip(batch, results):
                self._record_result(config, result)
                
        # Generate report
        return self._generate_report()
    
    async def _run_single_test(self, exporter: str, protocol: str, scenario: str) -> Dict[str, Any]:
        """Run a single test configuration."""
        start_time = datetime.now()
        
        try:
            # Configure telemetry
            config = self._create_config(exporter, protocol, scenario)
            
            # Initialize metrics integration
            integration = MetricsIntegration(**config)
            
            # Send test metrics
            test_metrics = self._generate_test_metrics()
            for metric in test_metrics:
                await integration.send_metric_async(metric)
                
            # Verify metrics were received
            if exporter != "none":
                received = await self._verify_metrics_received(exporter, len(test_metrics))
            else:
                received = True
                
            duration = (datetime.now() - start_time).total_seconds()
            
            return {
                "success": received,
                "duration": duration,
                "errors": []
            }
            
        except Exception as e:
            duration = (datetime.now() - start_time).total_seconds()
            return {
                "success": False,
                "duration": duration,
                "errors": [str(e)]
            }
#+END_SRC

** 4. Cost Analyzer (=src/cost_analyzer.py=)

Analyzes Claude Code usage costs and provides projections for budget planning.

*** Features
- *Multi-Model Support*: Haiku, Sonnet, Opus pricing
- *Cost Projections*: Daily, weekly, monthly estimates
- *Trend Analysis*: Identify cost patterns
- *Budget Alerts*: Threshold notifications

*** Implementation

#+BEGIN_SRC python
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import pandas as pd
import numpy as np
from prometheus_api_client import PrometheusConnect

class CostAnalyzer:
    """Analyze Claude Code costs and project future expenses."""
    
    # Model pricing per million tokens (as of 2024)
    MODEL_PRICING = {
        "claude-3-haiku": {"input": 0.25, "output": 1.25},
        "claude-3-sonnet": {"input": 3.00, "output": 15.00},
        "claude-3-opus": {"input": 15.00, "output": 75.00},
        "claude-opus-4": {"input": 15.00, "output": 75.00}  # Production model
    }
    
    def __init__(self, prometheus_url: str = "http://localhost:9090"):
        """Initialize cost analyzer with Prometheus connection."""
        self.prom = PrometheusConnect(url=prometheus_url, disable_ssl=True)
        
    def calculate_operation_cost(self, input_tokens: int, output_tokens: int, model: str) -> float:
        """Calculate cost for a single operation."""
        if model not in self.MODEL_PRICING:
            raise ValueError(f"Unknown model: {model}")
            
        pricing = self.MODEL_PRICING[model]
        input_cost = (input_tokens / 1_000_000) * pricing["input"]
        output_cost = (output_tokens / 1_000_000) * pricing["output"]
        
        return round(input_cost + output_cost, 4)
    
    def analyze_cost_trends(self, days: int = 7) -> Dict[str, Any]:
        """Analyze cost trends over specified period."""
        end_time = datetime.now()
        start_time = end_time - timedelta(days=days)
        
        # Query token usage
        query = '''
        sum by (model, token_type) (
            increase(claude_code_tokens_total[1d])
        )
        '''
        
        results = self.prom.custom_query_range(
            query=query,
            start_time=start_time,
            end_time=end_time,
            step="1h"
        )
        
        # Process results into cost data
        cost_data = self._process_cost_data(results)
        
        # Calculate statistics
        daily_costs = self._calculate_daily_costs(cost_data)
        
        return {
            "total_cost": sum(daily_costs.values()),
            "average_daily_cost": np.mean(list(daily_costs.values())),
            "peak_daily_cost": max(daily_costs.values()),
            "daily_breakdown": daily_costs,
            "projection_30d": self._project_costs(daily_costs, 30),
            "cost_by_model": self._aggregate_by_model(cost_data)
        }
    
    def generate_cost_report(self, output_path: str = "cost_report.json") -> None:
        """Generate comprehensive cost report."""
        report = {
            "generated_at": datetime.now().isoformat(),
            "analysis_period": "7d",
            "trends": self.analyze_cost_trends(7),
            "projections": {
                "next_24h": self._project_next_24h(),
                "next_7d": self._project_next_7d(),
                "next_30d": self._project_next_30d()
            },
            "recommendations": self._generate_recommendations()
        }
        
        with open(output_path, 'w') as f:
            json.dump(report, f, indent=2)
#+END_SRC

** 5. Session Analyzer (=src/session_analyzer.py=)

Analyzes Claude Code session patterns to optimize usage and identify inefficiencies.

*** Features
- *Peak Hour Analysis*: Identify high-usage periods
- *Session Duration Tracking*: Monitor session lengths
- *Token Efficiency Metrics*: Input/output ratios
- *Usage Pattern Recognition*: Identify workflows

*** Implementation

#+BEGIN_SRC python
from collections import defaultdict
from datetime import datetime, timedelta
import statistics

class SessionAnalyzer:
    """Analyze Claude Code session patterns and efficiency."""
    
    def __init__(self, prometheus_url: str = "http://localhost:9090"):
        """Initialize session analyzer."""
        self.prom = PrometheusConnect(url=prometheus_url, disable_ssl=True)
        
    def analyze_session_patterns(self, days: int = 7) -> Dict[str, Any]:
        """Analyze session patterns over specified period."""
        # Query session metrics
        sessions = self._query_sessions(days)
        
        # Analyze patterns
        patterns = {
            "peak_hours": self._identify_peak_hours(sessions),
            "average_duration": self._calculate_avg_duration(sessions),
            "session_distribution": self._analyze_distribution(sessions),
            "efficiency_metrics": self._calculate_efficiency(sessions)
        }
        
        return patterns
    
    def _identify_peak_hours(self, sessions: List[Dict]) -> Dict[int, float]:
        """Identify peak usage hours."""
        hour_usage = defaultdict(list)
        
        for session in sessions:
            hour = datetime.fromtimestamp(session["start_time"]).hour
            hour_usage[hour].append(session["token_count"])
            
        # Calculate average tokens per hour
        peak_hours = {}
        for hour, tokens in hour_usage.items():
            peak_hours[hour] = statistics.mean(tokens)
            
        # Sort by usage
        return dict(sorted(peak_hours.items(), key=lambda x: x[1], reverse=True))
    
    def _calculate_efficiency(self, sessions: List[Dict]) -> Dict[str, float]:
        """Calculate token efficiency metrics."""
        total_input = sum(s.get("input_tokens", 0) for s in sessions)
        total_output = sum(s.get("output_tokens", 0) for s in sessions)
        total_cache = sum(s.get("cache_tokens", 0) for s in sessions)
        
        return {
            "output_to_input_ratio": total_output / total_input if total_input > 0 else 0,
            "cache_hit_rate": total_cache / (total_input + total_cache) if (total_input + total_cache) > 0 else 0,
            "average_tokens_per_session": (total_input + total_output) / len(sessions) if sessions else 0
        }
#+END_SRC

* üì° API Documentation

** Metrics API

The Claude Code Metrics Lab exposes several APIs for metric collection and querying.

*** 1. Metric Submission API

*Endpoint*: =POST /api/v1/metrics=

*Request Body*:
#+BEGIN_SRC json
{
  "metrics": [
    {
      "name": "claude_code_tokens_total",
      "value": 1500,
      "timestamp": 1748050701,
      "labels": {
        "model": "claude-opus-4",
        "project": "my-project",
        "operation": "code_generation",
        "token_type": "input"
      }
    }
  ]
}
#+END_SRC

*Response*:
#+BEGIN_SRC json
{
  "status": "success",
  "processed": 1,
  "errors": []
}
#+END_SRC

*Error Response*:
#+BEGIN_SRC json
{
  "status": "error",
  "processed": 0,
  "errors": [
    {
      "metric_index": 0,
      "error": "Invalid model: claude-unknown",
      "validation_errors": ["model not in allowed list"]
    }
  ]
}
#+END_SRC

*** 2. Query API

*Endpoint*: =GET /api/v1/query=

*Query Parameters*:
- =metric=: Metric name (required)
- =start=: Start timestamp (optional, default: 1 hour ago)
- =end=: End timestamp (optional, default: now)
- =step=: Query resolution (optional, default: 60s)
- =labels=: Label filters as JSON (optional)

*Example Request*:
#+BEGIN_SRC bash
GET /api/v1/query?metric=claude_code_tokens_total&labels={"model":"claude-opus-4"}&step=300s
#+END_SRC

*Response*:
#+BEGIN_SRC json
{
  "status": "success",
  "data": {
    "resultType": "matrix",
    "result": [
      {
        "metric": {
          "model": "claude-opus-4",
          "project": "metrics-lab"
        },
        "values": [
          [1748050701, "1500"],
          [1748051001, "2100"],
          [1748051301, "1800"]
        ]
      }
    ]
  }
}
#+END_SRC

*** 3. Aggregation API

*Endpoint*: =GET /api/v1/aggregate=

*Query Parameters*:
- =metric=: Metric name (required)
- =aggregation=: Aggregation function (sum, avg, max, min, count)
- =groupby=: Comma-separated label names
- =period=: Time period (1h, 1d, 7d, 30d)

*Example Request*:
#+BEGIN_SRC bash
GET /api/v1/aggregate?metric=claude_code_cost_usd&aggregation=sum&groupby=model,project&period=1d
#+END_SRC

*Response*:
#+BEGIN_SRC json
{
  "status": "success",
  "data": [
    {
      "labels": {
        "model": "claude-opus-4",
        "project": "metrics-lab"
      },
      "value": 27.81,
      "period": "2024-01-20T00:00:00Z"
    }
  ]
}
#+END_SRC

** WebSocket API for Real-time Metrics

*Endpoint*: =ws://localhost:8080/api/v1/stream=

*Connection*:
#+BEGIN_SRC javascript
const ws = new WebSocket('ws://localhost:8080/api/v1/stream');

ws.onopen = () => {
  // Subscribe to specific metrics
  ws.send(JSON.stringify({
    action: 'subscribe',
    metrics: ['claude_code_tokens_total', 'claude_code_cost_usd'],
    filters: {
      model: 'claude-opus-4'
    }
  }));
};

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log('Metric update:', data);
};
#+END_SRC

*Message Format*:
#+BEGIN_SRC json
{
  "timestamp": 1748050701,
  "metric": "claude_code_tokens_total",
  "value": 1500,
  "labels": {
    "model": "claude-opus-4",
    "project": "my-project"
  }
}
#+END_SRC

* ‚öôÔ∏è Configuration Guide

** 1. Logging Proxy Configuration

The logging proxy is configured via =config/logging_proxy.yaml=:

#+BEGIN_SRC yaml
# Logging Proxy Configuration
version: "1.0"

# Validation rules
validation:
  # Allowed Claude models
  allowed_models:
    - "claude-3-haiku"
    - "claude-3-sonnet"
    - "claude-3-opus"
    - "claude-opus-4"
  
  # Metric name patterns
  metric_patterns:
    - "^claude_code_tokens_total$"
    - "^claude_code_cost_usd$"
    - "^claude_code_operations_total$"
    - "^claude_code_errors_total$"
    - "^claude_code_session_duration_seconds$"
  
  # Required labels
  required_labels:
    - "model"
    - "project"
  
  # Value constraints
  value_constraints:
    claude_code_tokens_total:
      min: 0
      max: 1000000  # 1M tokens max per metric
    claude_code_cost_usd:
      min: 0
      max: 100  # $100 max per metric

# Monitoring thresholds
monitoring:
  thresholds:
    # Token usage thresholds
    max_tokens_per_operation: 50000
    max_tokens_per_minute: 100000
    max_tokens_per_hour: 1000000
    
    # Cost thresholds
    max_cost_per_operation: 1.0  # $1.00
    max_cost_per_hour: 10.0      # $10.00
    max_cost_per_day: 100.0      # $100.00
    
    # Error thresholds
    max_error_rate: 0.05  # 5% error rate
    max_errors_per_minute: 10
  
  # Alert configuration
  alerts:
    enabled: true
    channels:
      - type: "console"
        severity: ["warning", "critical"]
      - type: "file"
        path: "alerts.log"
        severity: ["info", "warning", "critical"]
      - type: "webhook"
        url: "${ALERT_WEBHOOK_URL}"
        severity: ["critical"]

# Export configuration
export:
  # Batch settings
  batch_size: 100
  flush_interval: 30  # seconds
  
  # Output formats
  formats:
    - type: "json"
      path: "exports/proxy_logs/"
      rotation: "hourly"
      compression: true
    
    - type: "prometheus"
      endpoint: "localhost:9091"
      job: "claude_code_proxy"
      
    - type: "otlp"
      endpoint: "localhost:4317"
      protocol: "grpc"
      headers:
        "api-key": "${OTEL_API_KEY}"

# Debugging options
debug:
  enabled: true
  log_level: "INFO"
  payload_logging: true
  performance_tracking: true
  
  # Debug outputs
  outputs:
    - type: "console"
      format: "pretty"
    - type: "file"
      path: "debug.log"
      format: "json"

# Session configuration
session:
  # Session timeout
  timeout_minutes: 30
  
  # Session storage
  storage:
    type: "memory"  # or "redis" for distributed
    redis_url: "${REDIS_URL}"
  
  # Session analytics
  analytics:
    enabled: true
    track_patterns: true
    track_efficiency: true
#+END_SRC

** 2. OpenTelemetry Configuration

Configure OpenTelemetry exporters and collectors:

#+BEGIN_SRC yaml
# otel-collector-config.yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    timeout: 10s
    send_batch_size: 1024
    
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128
    
  attributes:
    actions:
      - key: environment
        value: production
        action: upsert
      - key: service.name
        value: claude-code
        action: upsert

exporters:
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: claude_code
    
  logging:
    loglevel: info
    
  otlp:
    endpoint: "${OTLP_ENDPOINT}"
    headers:
      api-key: "${OTLP_API_KEY}"

service:
  pipelines:
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch, attributes]
      exporters: [prometheus, logging]
#+END_SRC

** 3. Environment Variables

Create a =.env= file for sensitive configuration:

#+BEGIN_SRC bash
# API Keys
OTEL_API_KEY=your-api-key
ANTHROPIC_API_KEY=your-claude-api-key

# Endpoints
PROMETHEUS_URL=http://localhost:9090
GRAFANA_URL=http://localhost:3000
OTLP_ENDPOINT=localhost:4317

# Alert Configuration
ALERT_WEBHOOK_URL=https://your-webhook-url
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# Database
REDIS_URL=redis://localhost:6379
POSTGRES_URL=postgresql://user:pass@localhost:5432/metrics

# Feature Flags
ENABLE_COST_TRACKING=true
ENABLE_SESSION_ANALYTICS=true
ENABLE_PERFORMANCE_TRACKING=true

# Thresholds
MAX_DAILY_COST=100.00
MAX_HOURLY_TOKENS=1000000
#+END_SRC

* üöÄ Deployment Guide

** Prerequisites

- Python 3.9+
- Docker and Docker Compose
- Kubernetes (optional, for production)
- Prometheus
- Grafana

** Local Development Setup

1. *Clone the repository*:
#+BEGIN_SRC bash
git clone https://github.com/your-org/claude-code-metrics-lab.git
cd claude-code-metrics-lab
#+END_SRC

2. *Create virtual environment*:
#+BEGIN_SRC bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
#+END_SRC

3. *Install dependencies*:
#+BEGIN_SRC bash
pip install -r requirements.txt
#+END_SRC

4. *Start infrastructure with Docker Compose*:
#+BEGIN_SRC bash
docker-compose up -d
#+END_SRC

5. *Run the logging proxy*:
#+BEGIN_SRC bash
python src/logging_proxy.py
#+END_SRC

** Docker Deployment

Create a =Dockerfile=:

#+BEGIN_SRC dockerfile
FROM python:3.9-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m -u 1000 metrics && chown -R metrics:metrics /app
USER metrics

# Expose ports
EXPOSE 8080 9091

# Health check
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
  CMD python -c "import requests; requests.get('http://localhost:8080/health').raise_for_status()"

# Run the application
CMD ["python", "main.py"]
#+END_SRC

Build and run:
#+BEGIN_SRC bash
docker build -t claude-code-metrics:latest .
docker run -d \
  --name claude-metrics \
  -p 8080:8080 \
  -p 9091:9091 \
  -v $(pwd)/config:/app/config \
  -v $(pwd)/exports:/app/exports \
  claude-code-metrics:latest
#+END_SRC

** Kubernetes Deployment

1. *Create ConfigMap for configuration*:

#+BEGIN_SRC yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: claude-metrics-config
data:
  logging_proxy.yaml: |
    version: "1.0"
    validation:
      allowed_models:
        - "claude-opus-4"
    # ... rest of config
#+END_SRC

2. *Create Deployment*:

#+BEGIN_SRC yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: claude-metrics
  labels:
    app: claude-metrics
spec:
  replicas: 3
  selector:
    matchLabels:
      app: claude-metrics
  template:
    metadata:
      labels:
        app: claude-metrics
    spec:
      containers:
      - name: metrics
        image: claude-code-metrics:latest
        ports:
        - containerPort: 8080
          name: api
        - containerPort: 9091
          name: metrics
        env:
        - name: OTEL_API_KEY
          valueFrom:
            secretKeyRef:
              name: claude-metrics-secrets
              key: otel-api-key
        volumeMounts:
        - name: config
          mountPath: /app/config
        - name: exports
          mountPath: /app/exports
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: config
        configMap:
          name: claude-metrics-config
      - name: exports
        persistentVolumeClaim:
          claimName: metrics-exports-pvc
#+END_SRC

3. *Create Service*:

#+BEGIN_SRC yaml
apiVersion: v1
kind: Service
metadata:
  name: claude-metrics
spec:
  selector:
    app: claude-metrics
  ports:
  - name: api
    port: 8080
    targetPort: 8080
  - name: metrics
    port: 9091
    targetPort: 9091
  type: LoadBalancer
#+END_SRC

4. *Deploy to Kubernetes*:

#+BEGIN_SRC bash
kubectl apply -f k8s/
kubectl rollout status deployment/claude-metrics
#+END_SRC

** Production Considerations

1. *High Availability*:
   - Run multiple replicas (minimum 3)
   - Use anti-affinity rules to spread across nodes
   - Implement circuit breakers for external dependencies

2. *Security*:
   - Use TLS for all communications
   - Rotate API keys regularly
   - Implement RBAC for Kubernetes
   - Use network policies to restrict traffic

3. *Monitoring*:
   - Set up Prometheus alerts
   - Configure Grafana dashboards
   - Implement distributed tracing
   - Set up log aggregation

4. *Performance*:
   - Use Redis for session storage
   - Implement connection pooling
   - Configure appropriate resource limits
   - Use horizontal pod autoscaling

5. *Backup and Recovery*:
   - Regular exports of metrics data
   - Automated backups of configuration
   - Disaster recovery procedures
   - Point-in-time recovery capability

* üíª Code Examples

** 1. Basic Metric Collection

#+BEGIN_SRC python
from src.metrics_integration import MetricsIntegration

# Initialize metrics
metrics = MetricsIntegration()

# Record a code generation operation
metrics.record_operation(
    operation_type="code_generation",
    tokens=1500,
    cost=0.0225,  # $0.0225
    duration=2.5,   # 2.5 seconds
    model="claude-opus-4"
)

# Record with additional context
metrics.record_operation_with_context(
    operation_type="code_review",
    tokens=800,
    cost=0.012,
    duration=1.8,
    model="claude-opus-4",
    context={
        "file_count": 5,
        "lines_reviewed": 250,
        "issues_found": 3
    }
)
#+END_SRC

** 2. Session Tracking

#+BEGIN_SRC python
from src.logging_proxy import LoggingProxy

# Initialize proxy
proxy = LoggingProxy()

# Start a session
session = proxy.start_session(project="my-app")

# Track operations within session
with session:
    # Operation 1: Read files
    session.record_metric({
        "name": "claude_code_operations_total",
        "value": 1,
        "labels": {
            "operation": "file_read",
            "tool": "Read"
        }
    })
    
    # Operation 2: Generate code
    session.record_metric({
        "name": "claude_code_tokens_total",
        "value": 2500,
        "labels": {
            "operation": "code_generation",
            "token_type": "output"
        }
    })
    
# Session automatically closed and metrics exported
#+END_SRC

** 3. Cost Monitoring

#+BEGIN_SRC python
from src.cost_analyzer import CostAnalyzer

# Initialize analyzer
analyzer = CostAnalyzer()

# Monitor operation cost
def monitored_operation(func):
    """Decorator to monitor operation costs."""
    def wrapper(*args, **kwargs):
        # Record start
        start_tokens = get_current_token_count()
        
        # Execute operation
        result = func(*args, **kwargs)
        
        # Calculate cost
        end_tokens = get_current_token_count()
        tokens_used = end_tokens - start_tokens
        cost = analyzer.calculate_operation_cost(
            input_tokens=tokens_used["input"],
            output_tokens=tokens_used["output"],
            model=kwargs.get("model", "claude-opus-4")
        )
        
        # Check threshold
        if cost > 0.10:  # $0.10 threshold
            send_alert(f"High cost operation: ${cost:.2f}")
            
        return result
    return wrapper

@monitored_operation
def generate_complex_code(prompt: str, model: str = "claude-opus-4"):
    """Generate code with cost monitoring."""
    # Your code generation logic here
    pass
#+END_SRC

** 4. Real-time Dashboard Updates

#+BEGIN_SRC python
import asyncio
from datetime import datetime

async def stream_metrics_to_dashboard():
    """Stream real-time metrics to dashboard."""
    async with websockets.connect('ws://localhost:8080/api/v1/stream') as ws:
        # Subscribe to metrics
        await ws.send(json.dumps({
            "action": "subscribe",
            "metrics": ["claude_code_tokens_total", "claude_code_cost_usd"]
        }))
        
        # Process incoming metrics
        async for message in ws:
            metric = json.loads(message)
            
            # Update dashboard
            update_dashboard_widget(
                widget_id=f"{metric['name']}_gauge",
                value=metric['value'],
                labels=metric['labels']
            )
            
            # Check for anomalies
            if metric['name'] == 'claude_code_cost_usd' and metric['value'] > 1.0:
                trigger_cost_alert(metric)

# Run the streamer
asyncio.run(stream_metrics_to_dashboard())
#+END_SRC

** 5. Batch Processing

#+BEGIN_SRC python
from src.logging_proxy import LoggingProxy
import time

class BatchMetricProcessor:
    """Process metrics in batches for efficiency."""
    
    def __init__(self, batch_size: int = 100, flush_interval: int = 30):
        self.proxy = LoggingProxy()
        self.batch = []
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.last_flush = time.time()
        
    def add_metric(self, metric: dict):
        """Add metric to batch."""
        self.batch.append(metric)
        
        # Check if we should flush
        if len(self.batch) >= self.batch_size or \
           (time.time() - self.last_flush) > self.flush_interval:
            self.flush()
            
    def flush(self):
        """Flush all pending metrics."""
        if not self.batch:
            return
            
        # Process batch
        for metric in self.batch:
            self.proxy.process_metric(metric)
            
        # Export metrics
        self.proxy.export_metrics()
        
        # Reset
        self.batch = []
        self.last_flush = time.time()

# Usage
processor = BatchMetricProcessor()

# Add metrics
for i in range(1000):
    processor.add_metric({
        "name": "claude_code_operations_total",
        "value": 1,
        "timestamp": int(time.time()),
        "labels": {
            "operation": "test",
            "batch_id": str(i // 100)
        }
    })

# Final flush
processor.flush()
#+END_SRC

** 6. Custom Metric Types

#+BEGIN_SRC python
from opentelemetry import metrics
from typing import Callable

class CustomMetrics:
    """Define custom metric types for Claude Code."""
    
    def __init__(self, meter):
        self.meter = meter
        self._create_custom_metrics()
        
    def _create_custom_metrics(self):
        """Create custom metric instruments."""
        # Token efficiency ratio
        self.token_efficiency = self.meter.create_observable_gauge(
            name="claude_code_token_efficiency",
            description="Ratio of output to input tokens",
            unit="ratio",
            callback=self._calculate_token_efficiency
        )
        
        # Cost per operation histogram
        self.cost_histogram = self.meter.create_histogram(
            name="claude_code_cost_per_operation",
            description="Distribution of operation costs",
            unit="USD"
        )
        
        # Cache hit rate
        self.cache_hit_rate = self.meter.create_observable_gauge(
            name="claude_code_cache_hit_rate",
            description="Percentage of cache hits",
            unit="percent",
            callback=self._calculate_cache_hit_rate
        )
        
    def _calculate_token_efficiency(self, options):
        """Calculate token efficiency ratio."""
        # Query recent metrics
        input_tokens = query_metric_sum("claude_code_tokens_total", {"token_type": "input"})
        output_tokens = query_metric_sum("claude_code_tokens_total", {"token_type": "output"})
        
        if input_tokens > 0:
            efficiency = output_tokens / input_tokens
            yield metrics.Observation(efficiency, {"period": "5m"})
            
    def _calculate_cache_hit_rate(self, options):
        """Calculate cache hit rate."""
        cache_hits = query_metric_sum("claude_code_cache_hits_total")
        total_requests = query_metric_sum("claude_code_requests_total")
        
        if total_requests > 0:
            hit_rate = (cache_hits / total_requests) * 100
            yield metrics.Observation(hit_rate, {"period": "5m"})
#+END_SRC

* üìä Monitoring and Dashboards

** Dashboard Architecture

The Claude Code Metrics Lab includes a comprehensive dashboard system built on Grafana with template-based generation.

*** Dashboard Types

1. *Overview Dashboard*
   - Real-time token usage
   - Cost tracking
   - Session activity
   - Error rates
   - Tool usage distribution

2. *Cost Analysis Dashboard*
   - Cost by model
   - Hourly/daily/monthly trends
   - Cost projections
   - Budget tracking
   - Anomaly detection

3. *Performance Dashboard*
   - Operation latency
   - Token throughput
   - Cache hit rates
   - Error analysis
   - Resource utilization

** Dashboard Generation

Dashboards are generated using Jinja2 templates:

#+BEGIN_SRC python
from scripts.generate_dashboards import DashboardGenerator

# Initialize generator
generator = DashboardGenerator(
    template_dir="dashboards/templates",
    output_dir="dashboards/generated"
)

# Generate all dashboards
generator.generate_all_dashboards(
    environment="production",
    datasource="Prometheus"
)

# Generate specific dashboard with custom variables
generator.generate_dashboard(
    template="cost-tracking.template.json",
    output="cost-tracking-prod.json",
    variables={
        "refresh_interval": "30s",
        "default_time_range": "24h",
        "cost_threshold": 100.0
    }
)
#+END_SRC

** Key Metrics and Visualizations

*** 1. Token Usage Metrics

#+BEGIN_SRC promql
# Total tokens by model
sum by (model) (
  rate(claude_code_tokens_total[5m])
)

# Token efficiency ratio
sum(rate(claude_code_tokens_total{token_type="output"}[5m])) /
sum(rate(claude_code_tokens_total{token_type="input"}[5m]))

# Cache hit rate
sum(rate(claude_code_cache_hits_total[5m])) /
sum(rate(claude_code_requests_total[5m])) * 100
#+END_SRC

*** 2. Cost Metrics

#+BEGIN_SRC promql
# Cost per hour by model
sum by (model) (
  increase(claude_code_cost_usd[1h])
)

# Daily cost trend
sum(
  increase(claude_code_cost_usd[1d])
)

# Cost per operation percentiles
histogram_quantile(0.95,
  sum(rate(claude_code_cost_per_operation_bucket[5m])) by (le)
)
#+END_SRC

*** 3. Performance Metrics

#+BEGIN_SRC promql
# Operation latency by type
histogram_quantile(0.95,
  sum(rate(claude_code_operation_duration_bucket[5m])) by (operation, le)
)

# Error rate
sum(rate(claude_code_errors_total[5m])) /
sum(rate(claude_code_operations_total[5m])) * 100

# Active sessions
sum(claude_code_active_sessions)
#+END_SRC

** Alert Configuration

Configure alerts in Prometheus Alert Manager:

#+BEGIN_SRC yaml
groups:
- name: claude_code_alerts
  interval: 30s
  rules:
  - alert: HighCostPerHour
    expr: sum(increase(claude_code_cost_usd[1h])) > 10
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High Claude Code costs"
      description: "Claude Code costs exceeded $10 in the last hour: ${{ $value }}"
      
  - alert: HighErrorRate
    expr: |
      sum(rate(claude_code_errors_total[5m])) /
      sum(rate(claude_code_operations_total[5m])) * 100 > 5
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is {{ $value }}% (threshold: 5%)"
      
  - alert: TokenQuotaExceeded
    expr: sum(increase(claude_code_tokens_total[1h])) > 1000000
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Token quota exceeded"
      description: "Used {{ $value }} tokens in the last hour (quota: 1M)"
#+END_SRC

** Dashboard Best Practices

1. *Organize by Use Case*
   - Executive summary for stakeholders
   - Detailed technical views for engineers
   - Cost analysis for finance teams

2. *Use Appropriate Visualizations*
   - Gauges for current values
   - Time series for trends
   - Heatmaps for patterns
   - Tables for detailed breakdowns

3. *Implement Drill-downs*
   - Link from overview to detailed views
   - Filter by project, model, or time range
   - Provide context with annotations

4. *Performance Optimization*
   - Use recording rules for complex queries
   - Implement appropriate time ranges
   - Cache dashboard queries
   - Limit cardinality of labels

* üîç Troubleshooting

** Common Issues and Solutions

*** 1. Metrics Not Appearing in Prometheus

*Symptoms*: Metrics are sent but don't appear in Prometheus.

*Diagnosis*:
#+BEGIN_SRC bash
# Check if metrics are being exported
curl http://localhost:9091/metrics | grep claude_code

# Check Prometheus targets
curl http://localhost:9090/api/v1/targets

# Check OTLP collector logs
docker logs otlp-collector
#+END_SRC

*Solutions*:
- Verify exporter configuration
- Check network connectivity
- Ensure proper authentication
- Validate metric names and labels

*** 2. High Memory Usage

*Symptoms*: Application consuming excessive memory.

*Diagnosis*:
#+BEGIN_SRC python
import tracemalloc
import psutil

# Start memory profiling
tracemalloc.start()

# Your application code here

# Get memory statistics
current, peak = tracemalloc.get_traced_memory()
print(f"Current memory: {current / 1024 / 1024:.2f} MB")
print(f"Peak memory: {peak / 1024 / 1024:.2f} MB")

# System memory
process = psutil.Process()
print(f"RSS: {process.memory_info().rss / 1024 / 1024:.2f} MB")
#+END_SRC

*Solutions*:
- Implement batch processing
- Use memory-efficient data structures
- Configure appropriate buffer sizes
- Enable garbage collection tuning

*** 3. Metric Validation Failures

*Symptoms*: Metrics rejected by validation.

*Diagnosis*:
#+BEGIN_SRC python
from src.logging_proxy import LoggingProxy

# Enable debug mode
proxy = LoggingProxy()
proxy.debug = True

# Test metric
test_metric = {
    "name": "claude_code_test",
    "value": -1,  # Invalid: negative value
    "timestamp": "invalid"  # Invalid: not an integer
}

# Validate and see detailed errors
result = proxy.validate_metric(test_metric)
print(proxy.get_validation_errors())
#+END_SRC

*Solutions*:
- Review metric schema
- Ensure proper data types
- Check required fields
- Validate label values

*** 4. Dashboard Performance Issues

*Symptoms*: Dashboards load slowly or timeout.

*Diagnosis*:
#+BEGIN_SRC promql
# Check query performance
# In Prometheus UI, use the "Graph" tab and check query duration

# Identify high-cardinality metrics
count by (__name__)({__name__=~"claude_code_.*"})

# Check metric cardinality
count(count by (model, project, operation) (claude_code_tokens_total))
#+END_SRC

*Solutions*:
- Use recording rules for complex queries
- Limit time ranges
- Reduce label cardinality
- Implement query caching

*** 5. Cost Calculation Discrepancies

*Symptoms*: Calculated costs don't match actual billing.

*Diagnosis*:
#+BEGIN_SRC python
from src.cost_analyzer import CostAnalyzer

analyzer = CostAnalyzer()

# Verify pricing configuration
print(analyzer.MODEL_PRICING)

# Test calculation
test_cost = analyzer.calculate_operation_cost(
    input_tokens=1000,
    output_tokens=2000,
    model="claude-opus-4"
)
print(f"Test cost: ${test_cost:.4f}")

# Compare with actual
# For 1K input + 2K output on Opus:
# Input: 1000/1M * $15 = $0.015
# Output: 2000/1M * $75 = $0.150
# Total: $0.165
#+END_SRC

*Solutions*:
- Update pricing configuration
- Account for cache tokens
- Include all token types
- Verify model names

** Debug Mode

Enable comprehensive debugging:

#+BEGIN_SRC python
import logging
import os

# Set environment variable
os.environ["CLAUDE_METRICS_DEBUG"] = "true"

# Configure logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('debug.log'),
        logging.StreamHandler()
    ]
)

# Enable metric payload logging
from src.logging_proxy import LoggingProxy
proxy = LoggingProxy()
proxy.config["debug"]["payload_logging"] = True
proxy.config["debug"]["performance_tracking"] = True
#+END_SRC

** Performance Profiling

Profile application performance:

#+BEGIN_SRC python
import cProfile
import pstats
from pstats import SortKey

# Profile code execution
profiler = cProfile.Profile()
profiler.enable()

# Your application code here
run_metric_collection()

profiler.disable()

# Generate report
stats = pstats.Stats(profiler)
stats.sort_stats(SortKey.CUMULATIVE)
stats.print_stats(20)  # Top 20 functions

# Save detailed profile
stats.dump_stats("profile_results.prof")
#+END_SRC

* ‚ùì FAQ

** General Questions

*Q: What is the Claude Code Metrics Lab?*
A: It's a comprehensive telemetry system and educational framework for monitoring Claude Code usage, costs, and performance. It provides production-ready tools for tracking AI-powered development tool metrics.

*Q: Why was this project created?*
A: During an overnight experiment, Claude Code spent $27.81 autonomously. This highlighted the need for proper monitoring and cost control of AI development tools.

*Q: What makes this different from standard monitoring solutions?*
A: This lab focuses specifically on AI development tool metrics, includes cost tracking with real pricing data, provides educational documentation, and has been tested with production Claude Code usage.

** Technical Questions

*Q: Which metrics exporters are supported?*
A: The lab supports OTLP (gRPC and HTTP), Prometheus, Console, Logging, and None (for testing).

*Q: Can I use this with other AI coding assistants?*
A: Yes, the architecture is extensible. You can modify the metric schemas and pricing configurations for other tools.

*Q: How accurate is the cost tracking?*
A: Cost tracking uses official Anthropic pricing and accounts for input, output, and cache tokens. Accuracy depends on proper metric collection.

*Q: What's the performance overhead?*
A: Minimal - typically less than 1% CPU and 50MB memory overhead when properly configured.

** Deployment Questions

*Q: Can I run this in production?*
A: Yes, the system is production-ready and has been tested with real Claude Code usage. Follow the deployment guide for best practices.

*Q: Do I need all components?*
A: No, you can start with just the logging proxy and console exporter for basic monitoring.

*Q: How do I scale for high volume?*
A: Use Redis for session storage, implement horizontal scaling with Kubernetes, and configure appropriate batch sizes.

*Q: Is there a cloud-hosted version?*
A: Currently, this is a self-hosted solution. Cloud deployment guides are provided for major platforms.

** Cost Questions

*Q: How much can Claude Code cost?*
A: We've observed operations ranging from $0.0007 to $1.44 each. Daily costs can exceed $25 with heavy usage.

*Q: How can I control costs?*
A: Set up threshold alerts, monitor token usage, use cheaper models when appropriate, and implement usage quotas.

*Q: What's the most expensive operation?*
A: Large code generation tasks with Claude Opus 4 can be expensive, especially when generating multiple files or complex architectures.

** Troubleshooting Questions

*Q: Why aren't my metrics showing up?*
A: Check exporter configuration, verify network connectivity, ensure metrics are properly formatted, and check Prometheus targets.

*Q: How do I debug metric validation errors?*
A: Enable debug mode in the logging proxy, check validation logs, and use the test matrix to verify configuration.

*Q: Can I modify the metric schemas?*
A: Yes, update the JSON schemas in the configuration files and ensure all components use the same schema.

** Integration Questions

*Q: How do I integrate with existing monitoring?*
A: Use OTLP exporters to send metrics to your existing observability platform, or configure Prometheus remote write.

*Q: Can I add custom metrics?*
A: Yes, extend the metric schemas and create new instruments using the OpenTelemetry API.

*Q: Is there an API for querying metrics?*
A: Yes, the lab provides REST and WebSocket APIs for real-time metric access and historical queries.

* ‚ú® Best Practices

** 1. Metric Design

*Use Consistent Naming*:
#+BEGIN_SRC python
# Good: Consistent prefix and units
claude_code_tokens_total
claude_code_cost_usd
claude_code_duration_seconds

# Bad: Inconsistent naming
tokens_claude
claude_price
operation_time
#+END_SRC

*Choose Appropriate Metric Types*:
- *Counter*: For cumulative values (tokens, operations, errors)
- *Gauge*: For current values (active sessions, queue size)
- *Histogram*: For distributions (latency, cost per operation)

*Limit Label Cardinality*:
#+BEGIN_SRC python
# Good: Bounded cardinality
labels = {
    "model": "claude-opus-4",  # Limited set of models
    "operation": "code_gen",   # Limited operation types
    "status": "success"        # success/failure
}

# Bad: Unbounded cardinality
labels = {
    "user_id": "12345",       # Unlimited users
    "session_id": "abc-xyz",  # Unique per session
    "timestamp": "1234567"    # Unique values
}
#+END_SRC

** 2. Cost Optimization

*Use Appropriate Models*:
#+BEGIN_SRC python
def select_model_for_task(task_type: str) -> str:
    """Select the most cost-effective model for the task."""
    model_selection = {
        "simple_completion": "claude-3-haiku",      # $0.25/$1.25 per 1M
        "code_review": "claude-3-sonnet",           # $3/$15 per 1M  
        "complex_generation": "claude-opus-4",      # $15/$75 per 1M
        "architecture_design": "claude-opus-4"
    }
    return model_selection.get(task_type, "claude-3-sonnet")
#+END_SRC

*Implement Token Limits*:
#+BEGIN_SRC python
def enforce_token_limits(prompt: str, max_tokens: int = 10000) -> str:
    """Enforce token limits to control costs."""
    estimated_tokens = len(prompt.split()) * 1.3  # Rough estimate
    
    if estimated_tokens > max_tokens:
        # Truncate or summarize
        return truncate_prompt(prompt, max_tokens)
    
    return prompt
#+END_SRC

*Cache Frequently Used Results*:
#+BEGIN_SRC python
from functools import lru_cache
import hashlib

@lru_cache(maxsize=1000)
def get_cached_response(prompt_hash: str) -> Optional[str]:
    """Check cache before making expensive API calls."""
    return redis_client.get(f"claude:cache:{prompt_hash}")

def generate_with_cache(prompt: str) -> str:
    """Generate response with caching."""
    prompt_hash = hashlib.sha256(prompt.encode()).hexdigest()
    
    # Check cache
    cached = get_cached_response(prompt_hash)
    if cached:
        record_cache_hit()
        return cached
    
    # Generate new response
    response = generate_response(prompt)
    cache_response(prompt_hash, response)
    return response
#+END_SRC

** 3. Monitoring Best Practices

*Set Up Proactive Alerts*:
#+BEGIN_SRC yaml
# Alert before hitting limits
- alert: ApproachingDailyCostLimit
  expr: sum(increase(claude_code_cost_usd[20h])) > 80
  annotations:
    summary: "Approaching daily cost limit"
    description: "Current 20h cost: ${{ $value }}, limit: $100"
#+END_SRC

*Track Efficiency Metrics*:
#+BEGIN_SRC python
def calculate_efficiency_score() -> float:
    """Calculate overall efficiency score."""
    metrics = {
        "cache_hit_rate": get_cache_hit_rate(),
        "token_efficiency": get_output_to_input_ratio(),
        "error_rate": get_error_rate(),
        "avg_operation_cost": get_average_operation_cost()
    }
    
    # Weighted score
    score = (
        metrics["cache_hit_rate"] * 0.3 +
        metrics["token_efficiency"] * 0.2 +
        (1 - metrics["error_rate"]) * 0.3 +
        (1 / metrics["avg_operation_cost"]) * 0.2
    )
    
    return score
#+END_SRC

*Regular Monitoring Reviews*:
#+BEGIN_SRC python
def generate_weekly_report():
    """Generate weekly monitoring report."""
    report = {
        "period": "last_7d",
        "total_cost": get_total_cost(days=7),
        "total_operations": get_operation_count(days=7),
        "average_cost_per_op": get_average_cost(days=7),
        "most_expensive_ops": get_top_expensive_operations(limit=10),
        "error_summary": get_error_summary(days=7),
        "efficiency_trends": get_efficiency_trends(days=7),
        "recommendations": generate_cost_recommendations()
    }
    
    return report
#+END_SRC

** 4. Security Best Practices

*Secure API Keys*:
#+BEGIN_SRC python
import os
from cryptography.fernet import Fernet

class SecureConfig:
    """Secure configuration management."""
    
    def __init__(self):
        self.cipher = Fernet(os.environ["ENCRYPTION_KEY"].encode())
        
    def get_api_key(self, service: str) -> str:
        """Get decrypted API key."""
        encrypted = os.environ[f"{service.upper()}_API_KEY_ENCRYPTED"]
        return self.cipher.decrypt(encrypted.encode()).decode()
#+END_SRC

*Implement Rate Limiting*:
#+BEGIN_SRC python
from collections import defaultdict
import time

class RateLimiter:
    """Rate limiter for API endpoints."""
    
    def __init__(self, requests_per_minute: int = 60):
        self.requests_per_minute = requests_per_minute
        self.requests = defaultdict(list)
        
    def check_rate_limit(self, client_id: str) -> bool:
        """Check if client has exceeded rate limit."""
        now = time.time()
        minute_ago = now - 60
        
        # Clean old requests
        self.requests[client_id] = [
            req_time for req_time in self.requests[client_id]
            if req_time > minute_ago
        ]
        
        # Check limit
        if len(self.requests[client_id]) >= self.requests_per_minute:
            return False
            
        # Record request
        self.requests[client_id].append(now)
        return True
#+END_SRC

*Audit Logging*:
#+BEGIN_SRC python
import json
from datetime import datetime

class AuditLogger:
    """Audit logger for security events."""
    
    def log_event(self, event_type: str, details: dict):
        """Log security-relevant events."""
        event = {
            "timestamp": datetime.now().isoformat(),
            "event_type": event_type,
            "details": details,
            "environment": os.environ.get("ENVIRONMENT", "unknown")
        }
        
        # Log to secure storage
        with open("/secure/audit.log", "a") as f:
            f.write(json.dumps(event) + "\n")
            
        # Alert on critical events
        if event_type in ["unauthorized_access", "api_key_leaked"]:
            send_security_alert(event)
#+END_SRC

* ‚ö° Performance Optimization

** 1. Metric Collection Optimization

*Batch Processing*:
#+BEGIN_SRC python
class OptimizedMetricCollector:
    """Optimized metric collection with batching."""
    
    def __init__(self, batch_size: int = 100, flush_interval: int = 30):
        self.batch_size = batch_size
        self.flush_interval = flush_interval
        self.buffer = []
        self.last_flush = time.time()
        self.lock = threading.Lock()
        
        # Start background flusher
        self.flusher = threading.Thread(target=self._background_flush)
        self.flusher.daemon = True
        self.flusher.start()
        
    def add_metric(self, metric: dict):
        """Add metric to buffer."""
        with self.lock:
            self.buffer.append(metric)
            
            if len(self.buffer) >= self.batch_size:
                self._flush()
                
    def _flush(self):
        """Flush metrics buffer."""
        if not self.buffer:
            return
            
        # Process batch
        metrics_to_send = self.buffer[:]
        self.buffer = []
        
        # Send asynchronously
        asyncio.create_task(self._send_batch(metrics_to_send))
        
    async def _send_batch(self, metrics: list):
        """Send metric batch efficiently."""
        # Compress if large
        if len(metrics) > 1000:
            compressed = gzip.compress(json.dumps(metrics).encode())
            await send_compressed_metrics(compressed)
        else:
            await send_metrics(metrics)
#+END_SRC

*Connection Pooling*:
#+BEGIN_SRC python
from urllib3 import PoolManager
import aiohttp

class ConnectionPool:
    """Efficient connection pooling for metric exports."""
    
    def __init__(self, max_connections: int = 10):
        # Synchronous pool
        self.sync_pool = PoolManager(
            num_pools=5,
            maxsize=max_connections,
            retries=3,
            timeout=30.0
        )
        
        # Async pool
        self.async_session = None
        
    async def get_async_session(self):
        """Get or create async session."""
        if not self.async_session:
            connector = aiohttp.TCPConnector(
                limit=100,
                limit_per_host=30,
                ttl_dns_cache=300
            )
            self.async_session = aiohttp.ClientSession(
                connector=connector,
                timeout=aiohttp.ClientTimeout(total=30)
            )
        return self.async_session
#+END_SRC

** 2. Query Optimization

*Recording Rules*:
#+BEGIN_SRC yaml
# prometheus-recording-rules.yml
groups:
- name: claude_code_recording
  interval: 30s
  rules:
  # Pre-calculate expensive aggregations
  - record: claude_code:tokens_per_minute
    expr: |
      sum by (model, project) (
        rate(claude_code_tokens_total[1m])
      )
      
  - record: claude_code:cost_per_hour
    expr: |
      sum by (model, project) (
        increase(claude_code_cost_usd[1h])
      )
      
  - record: claude_code:operation_success_rate
    expr: |
      sum by (operation) (
        rate(claude_code_operations_total{status="success"}[5m])
      ) / 
      sum by (operation) (
        rate(claude_code_operations_total[5m])
      )
#+END_SRC

*Query Caching*:
#+BEGIN_SRC python
import redis
import pickle
from functools import wraps

class QueryCache:
    """Cache for expensive Prometheus queries."""
    
    def __init__(self, redis_url: str, ttl: int = 300):
        self.redis = redis.from_url(redis_url)
        self.ttl = ttl
        
    def cache_query(self, ttl: int = None):
        """Decorator to cache query results."""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # Generate cache key
                cache_key = f"query:{func.__name__}:{str(args)}:{str(kwargs)}"
                
                # Check cache
                cached = self.redis.get(cache_key)
                if cached:
                    return pickle.loads(cached)
                    
                # Execute query
                result = func(*args, **kwargs)
                
                # Cache result
                self.redis.setex(
                    cache_key,
                    ttl or self.ttl,
                    pickle.dumps(result)
                )
                
                return result
            return wrapper
        return decorator
#+END_SRC

** 3. Storage Optimization

*Retention Policies*:
#+BEGIN_SRC yaml
# prometheus.yml
global:
  scrape_interval: 30s
  evaluation_interval: 30s
  external_labels:
    environment: 'production'

# Storage configuration
storage:
  tsdb:
    retention.time: 30d
    retention.size: 100GB
    
# Downsampling rules
remote_write:
- url: http://thanos:10908/api/v1/receive
  write_relabel_configs:
  # Downsample high-frequency metrics
  - source_labels: [__name__]
    regex: 'claude_code_tokens_total'
    target_label: __tmp_sample_rate
    replacement: '0.1'  # Keep 10% of samples
#+END_SRC

*Data Compression*:
#+BEGIN_SRC python
class CompressedMetricStorage:
    """Compressed storage for historical metrics."""
    
    def store_metrics(self, metrics: list, timestamp: int):
        """Store metrics with compression."""
        # Group by metric type
        grouped = defaultdict(list)
        for metric in metrics:
            grouped[metric['name']].append(metric)
            
        # Compress each group
        for metric_name, metric_list in grouped.items():
            # Convert to efficient format
            data = {
                'timestamps': [m['timestamp'] for m in metric_list],
                'values': [m['value'] for m in metric_list],
                'labels': [m.get('labels', {}) for m in metric_list]
            }
            
            # Compress
            compressed = zlib.compress(
                msgpack.packb(data),
                level=9  # Maximum compression
            )
            
            # Store
            storage_key = f"metrics:{metric_name}:{timestamp}"
            self.storage.put(storage_key, compressed)
#+END_SRC

** 4. Dashboard Performance

*Optimize Queries*:
#+BEGIN_SRC javascript
// Good: Use recording rules and limit time range
const efficientQuery = `
  claude_code:tokens_per_minute{project="$project"}[$__range]
`;

// Bad: Complex calculation on raw metrics
const inefficientQuery = `
  sum by (model) (
    rate(claude_code_tokens_total[5m]) * 60
  ) / 
  sum by (model) (
    rate(claude_code_operations_total[5m])
  )
`;
#+END_SRC

*Implement Query Timeouts*:
#+BEGIN_SRC python
class DashboardQueryHandler:
    """Handle dashboard queries with timeouts."""
    
    async def execute_query(self, query: str, timeout: int = 30):
        """Execute query with timeout."""
        try:
            result = await asyncio.wait_for(
                self.prometheus.query_async(query),
                timeout=timeout
            )
            return result
        except asyncio.TimeoutError:
            # Return cached result or empty
            cached = self.get_cached_result(query)
            if cached:
                return cached
            raise QueryTimeoutError(f"Query timed out after {timeout}s")
#+END_SRC

* Conclusion

The Claude Code Metrics Lab provides a comprehensive solution for monitoring, analyzing, and optimizing AI-powered development tool usage. Through its educational approach, production-tested components, and real-world data, it offers invaluable insights into the costs and patterns of autonomous AI operations.

Key takeaways:
- *Cost Awareness is Critical*: Operations can vary by 2,000x in cost
- *Systematic Monitoring*: Proper telemetry can prevent unexpected expenses
- *Educational Value*: Understanding the "why" behind telemetry design
- *Production Ready*: Tested with real Claude Code usage
- *Extensible Architecture*: Adaptable to other AI tools and use cases

By implementing the practices and tools described in this guide, you can effectively monitor and control your AI development tool usage while gaining deep insights into operational patterns and costs.

For updates, contributions, and support, visit the project repository and join our community of developers working to make AI tool usage more transparent and cost-effective.